# -*- coding: utf-8 -*-
"""whisperx_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11lp-MthmuxyULpl854sx1jJQhLzbS51s

# CONFIG
"""

LESSON_FOLDER = "L01"
TRANSCRIPT_FOLDER = "transcript"

!gdown 1iSbXiFowpUa76QsF42pYMPDaNBtR8Eek

"""# SETTING"""

!pip install transformers accelerate --quiet

!pip install whisperx

import os
import torch
from transformers import pipeline
import json
from tqdm import tqdm
import whisperx

os.system(f'unzip {LESSON_FOLDER}.zip')
os.system(f'rm -rf {LESSON_FOLDER}.zip')

"""# PROCESS"""

device = "cuda" if torch.cuda.is_available() else "cpu"

transcriber = whisperx.load_model("large-v2", device=device, compute_type="int8")
corrector = pipeline("text2text-generation", model="bmd1905/vietnamese-correction")

def correct_transcript(corrector, transcript):
    return corrector(transcript, max_length=512, do_sample=False)[0]["generated_text"]

def transcribe(transcriber, corrector, video_path):
    audio = whisperx.load_audio(video_path)
    transcripts = transcriber.transcribe(audio, batch_size=2)
    transcripts = [correct_transcript(corrector, transcript['text']) for transcript in transcripts['segments']]

    return " ".join(transcripts)

os.makedirs(TRANSCRIPT_FOLDER, exist_ok=True)
transcript_lesson_path = os.path.join(TRANSCRIPT_FOLDER, LESSON_FOLDER)
os.makedirs(transcript_lesson_path, exist_ok=True)

for video_folder in sorted(os.listdir(LESSON_FOLDER)):
    print(f"Processing {video_folder}")
    transcript_video_path = os.path.join(transcript_lesson_path, video_folder)
    os.makedirs(transcript_lesson_path, exist_ok=True)
    video_folder_path = os.path.join(LESSON_FOLDER, video_folder)
    results = []
    for subvideo in tqdm(sorted(os.listdir(video_folder_path))):
        if subvideo.endswith(".mp4"):
            subvideo_path = os.path.join(video_folder_path, subvideo)
            transcript = transcribe(transcriber, corrector, subvideo_path)
            transcript = correct_transcript(corrector, transcript)
            results.append({
                "subvideo": subvideo_path,
                "transcript": transcript,
            })
    output_json_path = os.path.join(transcript_lesson_path, f"{LESSON_FOLDER}_{video_folder}_transcript.json")
    with open(output_json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=4)