# Text-to-Video Search with Vision-Language Models

This project allows you to search videos based on text descriptions using Vision-Language Models (VLMs) like CLIP. It supports both Vietnamese and English queries through an integrated translation module.

## ðŸŒŸ Features

- **Cross-modal search**: Search for videos using either text descriptions or example images
- **Multilingual support**: Automatic translation from Vietnamese to English
- **Modular design**: Easily extendable with new VLM models
- **Efficient retrieval**: Fast similarity search using FAISS indices
- **API-based interface**: Simple REST API built with FastAPI
- **Keyframe extraction**: Automatic extraction of keyframes from videos

## ðŸ“‹ Project Structure

```
project_root/
â”‚
â”œâ”€â”€ data_preparation.py        # Functions to build and save FAISS index from images/keyframes
â”œâ”€â”€ faiss_index.py             # FaissIndex class for search operations
â”œâ”€â”€ translation.py             # Translation module (Vietnamese -> English)
â”œâ”€â”€ vlm.py                     # Abstract BaseVLM class and model implementations (CLIP, BLIP)
â”œâ”€â”€ app.py                     # FastAPI application
â”‚
â”œâ”€â”€ data/                      # Data directory
â”‚   â””â”€â”€ keyframes/             # Directory for extracted keyframes
â”‚
â”œâ”€â”€ faiss_index/               # Directory for FAISS index files
â”‚
â”œâ”€â”€ requirements.txt           # Project dependencies
â””â”€â”€ README.md                  # This file
```

## ðŸ”§ Installation

1. Clone the repository:
```bash
git clone https://github.com/QuocThinh73/HCMAI2025.git
cd HCMAI2025
```

2. Install the requirements:
```bash
pip install -r requirements.txt
```

3. Create necessary directories:
```bash
mkdir -p data/keyframes faiss_index
```

## ðŸš€ Usage

### 1. Extract keyframes and build index

```python

```

### 2. Run the API

Start the FastAPI application:

```bash
python app.py
```

The API will be available at http://localhost:8000, with interactive documentation at http://localhost:8000/docs.

## ðŸ“¦ Extending with New Models

To add a new Vision-Language Model, simply create a new class in `vlm.py` that inherits from `BaseVLM`:

```python
class NewModel(BaseVLM):
    def __init__(self, model_name: str = "path/to/model"):
        # Initialize your model
        
    def encode_text(self, text: str) -> np.ndarray:
        # Implement text encoding
        
    def encode_image(self, image: Image.Image) -> np.ndarray:
        # Implement image encoding
```